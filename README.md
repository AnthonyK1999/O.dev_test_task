# O.dev_test_task
Отчёт

Анализ признаков и работа с ними:
1. подтвердилось, что 2 фичи будут бесполезны для моделей:
- Gender
- purpose_of_travel
Данные фичи оказались внизу списка встроенного get_feature_importance у CatBoost,
и внизу списка важности фичей, рассчитанной с помощью shap, а также на гистограммах
плотностей видно, что от данной фичи не зависит целевая переменная (таргет).
Вследствие вышеперечисленного данные фичи были удалены.
2. По гистограммам плотностей видно, что таргет не зависит от признаков линейно, поэтому 
было принято решение пользоваться деревянными моделями и методом опорных векторов,
а не строить линейную регрессию
3. Неудаленные признаки имели низкую линейную корреляцию,
поэтому фильтрация признаков далее не проводилась
4. Категориальные фичи были преобразованы в целочисленные с помощью LabelEncoder,
чтобы построить гистограммы плотностей и у метода опорных векторов не возникало конфликтов
с категориальными фичами
5. Выборка сбалансирована по 2 классам, но не идеально, поэтому
но было принято решение использовать ROC AUC
6. Удаление фичей вполне интерпретируемо:
- Gender: нельзя выделить более 'привередливый' пол
- purpose_of_travel: цель поездки никак не влияет на удовлетворенность отелем

Модель и качество:

1. Была построена модель-ансамбль, использовался метод стекинга, в котором в качестве 
метамодели была выбрана линейная регрессия, а в качестве базовых моделей:
- градиентный бустинг (CatBoostClassifier)
- случайный лес (RandomForestClassifier из библиотеки sklearn)
- метод опорных векторов с предварительной нормализацией
(LinearSVC, StandardScaler из библиотеки sklearn)
2. Модель показала высокое качество:
ROC AUC = 0.991

Идеи:

1. Подбор гиперпараметров с помощью (Randomized)GridSearch или optuna
2. Использовать Lama automl
3. Попробовать взять функцию от признаков (например, степень), и использовать их для предсказания 
линейной моделью
4. Использовать другие модели, например knn, tabnet, FCN
5. Провести более подробное исследование данных
6. Использовать pca или другие методы обработки признаков, однако тогда можем потерять их интерптетируемость
7. feature importance с помощью других методов, например, permutation, встроенный feature_importance
модели RandomForest или tabnet, L1-регуляризация
8. one-hot-encoding категориальных признаков



